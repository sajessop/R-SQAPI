
# The "r" way

# Load packages
```{r}
library(R6)
library(httr)
library(jsonlite)
library(getPass)
```

# Create class SQAPI with property: host 
```{r}
SQAPI <- R6Class("SQAPI", public = list(
  host = NULL,
  auth = NULL,
  initialize = function(host = NULL) {
    if (is.null(host)) {
      self$host <- "https://squidle.org"
    } else{
      self$host <- host
    }
    
    if (is.null(getOption("api_token"))) {
      self$auth <- getPass::getPass(msg = "Enter your API token: ")
      options(api_token = self$auth)
    } else {
      self$auth <- getOption("api_token")
    }
  }
))
```

# Helper function to recursively search list for key and return the associated value
```{r}
find_key <- function(lst, key) {
  if (is.list(lst)) {
    if (key %in% names(lst)) {
      return(lst[[key]])
    }
    for (sub in lst) {
      result <- find_key(sub, key)
      if (!is.null(result)) return(result)
    }
  }
  return(NULL)
}

# Example usage
find_key(my_params_5, "template")
```

# Helper function to construct host + endpoint
```{r}
base_url <- function(host, endpoint){
  url <- paste0(host,"/", endpoint)
  return(url)
}
```

# Function to make query filters
# accepts name, op, val as strings - see API for details on fields
```{r}
query_filter <- function(name,
                          op,
                          val = NULL) {
  # Create the filter list and exclude 'val' if NULL
  qfilter <- list(name = name, op = op)
  if (!is.null(val)){
    qfilter$val <- val
  }
  
  return(qfilter)
}
```

# Function to make query parameters
# template, disposition, include_columns, page, results_per_page are input as strings
# limit and offset are input as intergers
# group by is input as a string 
# order by is input as a vector containing two elements the first being the field and the second being direction (either "asc" or "desc")
# single is a boolean representing whether a single result is expected (I have not tested this)
```{r}
# WIP
query_params <- function(template = NULL,
                         disposition = NULL,
                         include_columns = NULL,
                         page = NULL,
                         results_per_page = NULL,
                         limit = NULL,
                         offset = NULL,
                         order_by = NULL,
                         group_by = NULL,
                         single = FALSE) {
  qparams <- list()
  q <- list()
  
  # Append to q list (parameters inside the q={} json string)
  
  # Handle 'order_by' as a character vector (e.g., c("field1", "asc"))
  json_order_by <- if (!is.null(order_by)) {
    # Check if order_by is a character vector with exactly two elements (field and direction)
    if (length(order_by) != 2 || !is.character(order_by)) {
      stop(
        "ERROR: order_by must be a character vector with exactly 2 elements, e.g., c('<fieldname>', '<order>')"
      )
    }
    order_by <- list(list(field = order_by[1], direction = order_by[2]))
    jsonlite::toJSON(order_by, auto_unbox = TRUE)
  } else {
    NULL
  }
  if (!is.null(json_order_by)) {
    q$order_by <- json_order_by
  }
  
  # Handle 'group_by' as a single field or a vector of fields
  json_group_by <- if (!is.null(group_by)) {
    if (is.character(group_by)) {
      # If it's a single field (string), make it a list
      group_by <- list(list(field = group_by))
    } else if (is.character(group_by) && length(group_by) > 1) {
      # If it's a vector of fields, process each field
      group_by <- lapply(group_by, function(x)
        list(field = x))
    } else {
      stop("ERROR: group_by must be a string or a character vector of field names.")
    }
    jsonlite::toJSON(group_by, auto_unbox = TRUE)
  } else {
    NULL
  }
  if (!is.null(json_group_by)) {
    q$group_by <- json_group_by
  }
  
  # Handle others
  if (!is.null(limit)) {
    q$limit <- limit
  }
  if (!is.null(offset)) {
    q$offset <- offset
  }
  if (!is.null(single) && single) {
    q$single <- TRUE
  }
  
  # Append to qparams list (parameters outside the q={} json string)
  # Handle include columns vector and convert to json
  json_include_columns <- if (!is.null(include_columns)) {
    jsonlite::toJSON(include_columns, auto_unbox = TRUE)
  } else {
    NULL
  }
  if (!is.null(json_include_columns)) {
    qparams$include_columns <- json_include_columns
  }
  
  # Add other parameters to the qparams list if not NULL
  for (param in c("template", "disposition", "page", "results_per_page")) {
    if (!is.null(get(param)))
      qparams[[param]] <- get(param)
  }
  return(list(q, qparams))
}
```

```{r}
# old working
query_params_old <- function(template = NULL,
                         disposition = NULL,
                         include_columns = NULL,
                         page = NULL,
                         results_per_page = NULL,
                         limit = NULL,
                         offset = NULL,
                         order_by = NULL,
                         group_by = NULL,
                         single = FALSE) {
  qparams <- list()
  q <- list()

# Append to q list (parameters inside the q={} json string)  
  
  # Handle 'order_by' as a character vector (e.g., c("field1", "asc"))
  json_order_by <- if (!is.null(order_by)) {
    # Check if order_by is a character vector with exactly two elements (field and direction)
    if (length(order_by) != 2 || !is.character(order_by)) {
      stop(
        "ERROR: order_by must be a character vector with exactly 2 elements, e.g., c('<fieldname>', '<order>')"
      )
    }
    order_by <- list(list(field = order_by[1], direction = order_by[2]))
    jsonlite::toJSON(order_by, auto_unbox = TRUE)
  } else {
    NULL
  }
  if (!is.null(json_order_by)) {
    q$order_by <- json_order_by
  }
  
  # Handle 'group_by' as a single field or a vector of fields
  json_group_by <- if (!is.null(group_by)) {
    if (is.character(group_by)) {
      # If it's a single field (string), make it a list
      group_by <- list(list(field = group_by))
    } else if (is.character(group_by) && length(group_by) > 1) {
      # If it's a vector of fields, process each field
      group_by <- lapply(group_by, function(x)
        list(field = x))
    } else {
      stop("ERROR: group_by must be a string or a character vector of field names.")
    }
    jsonlite::toJSON(group_by, auto_unbox = TRUE)
  } else {
    NULL
  }
  if (!is.null(json_group_by)) {
    q$group_by <- json_group_by
  }
  
  # Handle others 
    if (!is.null(limit)) {
    q$limit <- limit
  }
  if (!is.null(offset)) {
    q$offset <- offset
  }
  if (!is.null(single) && single) {
    q$single <- TRUE
  }
  
# Append to qparams list (parameters outside the q={} json string)    
   # Handle include columns vector and convert to json
  json_include_columns <- if (!is.null(include_columns)) {
    jsonlite::toJSON(include_columns, auto_unbox = TRUE)
  } else {
    NULL
  }
  if (!is.null(json_include_columns)) {
    qparams$include_columns <- json_include_columns
  }
  
  # Add other parameters to the qparams list if not NULL
  if (!is.null(template)) {
    qparams$template <- template
  }
  if (!is.null(disposition)) {
    qparams$disposition <- disposition
  }
  if (!is.null(page)) {
    qparams$page <- page
  }
  if (!is.null(results_per_page)) {
    qparams$results_per_page <- results_per_page
  }
  return(list(q, qparams))
}
```


```{r}
#WIP
append_url <- function(host,
                       endpoint,
                       query_filters = NULL,
                       query_parameters = NULL) {
  
  if (is.null(query_filters)) return(base_url(host, endpoint))

  # Wrap filters in a list
  filters <- list(filters = list(query_filters))

  # Initialize q list
  q <- list()

  # Process query parameters
  if (!is.null(query_parameters[[1]])) {
    q <- lapply(names(query_parameters[[1]]), function(param) {
      value <- query_parameters[[1]][[param]]
      if (!is.null(value)) {
        switch(param,
               "order_by" = jsonlite::fromJSON(value, simplifyDataFrame = FALSE),
               "group_by" = jsonlite::fromJSON(value, simplifyDataFrame = FALSE),
               value)
      }
    })
    names(q) <- names(query_parameters[[1]])
    q <- q[!sapply(q, is.null)]  # Remove NULL values
  }

  # Combine filters and q, then convert to JSON
  combined_q_json <- jsonlite::toJSON(c(filters, q), auto_unbox = TRUE)

  # Extract qparams (if they exist)
  qparams <- if (length(query_parameters) > 1) query_parameters[[2]] else list()

  # Construct URL
  url <- httr::parse_url(base_url(host, endpoint))

  # Append filters and parameters
  url$query <- c(list(q = combined_q_json), qparams)

  return(httr::build_url(url))
}
```

# Function to append query filters and paramaters to url
# input host as <nameofapiinstance>$host
# input endpoint as a string
# input query_filers and query_parameters as the *exact* output from the functions used to create them 
```{r}
## TO DO: use the find_key helper function rather than search by location. And use switch logic rather than if
append_url_old <- function(host,
                       endpoint,
                       query_filters = NULL,
                       query_parameters = NULL) {
  
  if (!is.null(query_filters)){
  # Finalise formatting of filters
  # Wrap in list called "filters"
  filters <- list(filters = list(query_filters))
  
  # Initialise q list
  q <- list()
  #Finalise formatting of remaining query string (q)
  if (!is.null(query_parameters) &&
      length(query_parameters[[1]]) > 0)
  {
    if (!is.null(query_parameters[[1]]$order_by)) {
      q$order_by <- jsonlite::fromJSON(query_parameters[[1]]$order_by, simplifyDataFrame = FALSE)
    }
    if (!is.null(query_parameters[[1]]$group_by)) {
      q$group_by <- jsonlite::fromJSON(query_parameters[[1]]$group_by, simplifyDataFrame = FALSE)
    }
    if (!is.null(query_parameters[[1]]$limit)) {
      q$limit <- query_parameters[[1]]$limit
    }
    if (!is.null(query_parameters[[1]]$offset)) {
      q$offset <- query_parameters[[1]]$offset
    }
    if (!is.null(query_parameters[[1]]$single)) {
      q$single <- query_parameters[[1]]$single
    }
  }
  
  # combine filters and q and convert to json
  combined_q <- c(filters, q)
  
  # Convert to JSON
  combined_q_json <- jsonlite::toJSON(combined_q, auto_unbox = TRUE)
  
  #Finalise formatting of qparams
  qparams <- if (!is.null(query_parameters) &&
                 length(query_parameters) > 1 &&
                 length(query_parameters[[2]]) > 0) {
    query_parameters[[2]]
  } else {
    list()
  }
  
  # Construct url
  base_url <- base_url(host, endpoint)
  url <- httr::parse_url(base_url)
  
  #Append filters and parameters
  url$query <- list(q = combined_q_json)
  if (length(qparams) > 0) {
    url$query <- c(url$query, qparams)
  }
  url <- httr::build_url(url)
  
  } else {
    url <- base_url(host, endpoint)
  }
  return(url)
}
```


# Function to make the VERB request to non export endpoint
# Can pipe url in from append_url function
# input verb as string eg "GET"
# input token as <nameofapiinstance>$auth
# filename as string ensuring file extenstion matched specified template (or the default json)
```{r}
## TO DO: add support for POST and PATCH verbs eg (if (verb == "POST") allow sending of json)
request <- function(url, verb, token) {
  response <- httr::VERB(
    verb = verb,
    url = url,
    config = httr::add_headers(Authorization = paste("Bearer", token))#,
    #write_disk(filename, overwrite = TRUE)
  )
  
  # Print status
  cat("Response Status Code:")
  print(response$status_code)
  
  ret_results <- response
  
  # Print response object
  print(ret_results)
  return(ret_results)
}
```


# Function to make the VERB request to export endpoint
# Can pipe url in from append_url function
# input verb as string eg "GET"
# input token as <nameofapiinstance>$auth
# poll=TRUE for export endpoints
# filename as string ensuring file extenstion matched specified template (or the default json)
# metadata_filename as string - only need if template has been set as data.csv or dataframe.csv
```{r}
## TO DO: add support for POST and PATCH verbs eg (if (verb == "POST") allow sending of json)
## Note: Metadata only writes if template has been set as data.csv or dataframe.csv
# name the metadata.json as filename_metadata.json
export <- function(url,
                   verb,
                   token,
                   poll = TRUE,
                   write_disk = FALSE,
                   filename,
                   metadata_filename = "metadata.json") {
  # Initial request
  if (write_disk) {
    response <- httr::VERB(
      verb = verb,
      url = url,
      config = httr::add_headers(Authorization = paste("Bearer", token)),
      httr::write_disk(filename, overwrite = TRUE)
    )
  } else {
    response <- httr::VERB(
      verb = verb,
      url = url,
      config = httr::add_headers(Authorization = paste("Bearer", token)),
      httr::write_memory()
    )
  }
  
  # Extract JSON response
  json <- jsonlite::fromJSON(
    content(response, 'text', encoding = "UTF-8"),
    simplifyVector = TRUE,
    flatten = TRUE
  )
  
  if (poll) {
    # Polling
    results_response <- NULL
    
    # Define URLs
    host <- "https://squidle.org"
    status_url <- paste0(host, json$status_url)
    result_url <- paste0(host, json$result_url)
    
    print(json$message)
    print(paste0("Status URL: ", status_url))
    print(paste0("Results URL: ", result_url))
    
    # Progress Bar
    pbar <- txtProgressBar(min = 0, max = 100, style = 3)
    
    while (TRUE) {
      # Check status
      status_response <- httr::VERB(
        verb = verb,
        url = status_url,
        config = httr::add_headers(Authorization = paste("Bearer", token))
      )
      
      json_status_response <- jsonlite::fromJSON(
        content(status_response, 'text', encoding = "UTF-8"),
        simplifyVector = TRUE,
        flatten = TRUE
      )
      
      # If the result is ready
      if (json_status_response$result_available || json_status_response$status == "done") {
        if (write_disk) {
          results_response <- httr::VERB(
            verb = verb,
            url = result_url,
            config = httr::add_headers(Authorization = paste("Bearer", token)),
            httr::write_disk(filename, overwrite = TRUE)  # Correct result URL
          )
        } else {
          results_response <- httr::VERB(
            verb = verb,
            url = result_url,
            config = httr::add_headers(Authorization = paste("Bearer", token)),
            httr::write_memory()
          )
        }
        
        setTxtProgressBar(pbar, 100)  # Set progress to 100% when done
        break
      } else if (json_status_response$status == "error") {
        close(pbar)
        stop("Error in processing the request.")
      }
      
      # Calculate progress
      stages <- json_status_response$progress
      total_iterations <- sum(sapply(stages, function(stage) if (!is.null(stage$iteration_count)) stage$iteration_count else 0))
      completed_iterations <- sum(sapply(stages, function(stage) if (!is.null(stage$iteration)) stage$iteration else 0))
      
      overall_progress <- if (total_iterations > 0) (completed_iterations / total_iterations) * 100 else 0
      setTxtProgressBar(pbar, overall_progress)
      
      Sys.sleep(1)  # Avoid excessive polling
    }
    
    close(pbar)
    ret_results <- results_response
  } else {
    ret_results <- response
  }
  
  # Handle metadata if it's a CSV file
  if (grepl("data.csv|dataframe.csv", url)) {
    meta <- ret_results$headers$`x-content-metadata`
    writeLines(meta, metadata_filename)  
    cat("See metadata file: ", metadata_filename, "\n")
  }
  
  cat("\nResponse Status Code: ", response$status_code, "\n")
  return(ret_results)
}

```


```{r}

parse <- function(response, query_params = NULL) {
  
  if (is.null(query_params)){
    template <- "default"}
  # Finds value associated with key "template"
  template <- find_key(query_params, "template")
  # Handle null templace as "default"
    if (is.null(template)) {
    template <- "default"
  }
  parsed <- switch(template,
                   "data.csv" = {
                     raw_text <- rawToChar(response$content)
                     read.csv(textConnection(raw_text))
                   },
                   "dataframe.json" = {
                     jsonlite::fromJSON(httr::content(response, "text", encoding = "UTF-8"))
                   },
                   {
                     "default" = 
                     {jsonlite::fromJSON(httr::content(response, "text", encoding = "UTF-8"))}
                   })
  
  return(parsed)
}
```


# Updated usage
```{r}
# Lib for pipes
library(magrittr)

# Initialize api to handle authentication (using default host)
## Will prompt for token in console
api <- SQAPI$new()

# Example 0 - A simple query
{
  # Create filters
  my_filters <- query_filter(name = "id", op = "eq", val = "5432")
  # Append filters and send request
  r <- append_url(api$host, "api/annotation_set", my_filters) %>% request("GET", api$auth)
  
  # parse
  p <- parse(r)
  
  # look at url
  my_url <- append_url(api$host, "api/annotation_set", my_filters)
  cat(URLdecode(my_url))
}

# Example 1 - A nested query to Get all media_collections that contain media from a specific campaign matching the key "Batemans201011"

  # Create filters (nested)
  my_filters1 <- query_filter(
    name = "media",
    op = "any",
    val = query_filter(
      name = "deployment",
      op = "has",
      val = query_filter(
        name = "campaign",
        op = "has",
        val = query_filter(name = "key", op = "eq", val = "Batemans201011")
      )
    )
  )
  # Append filters and send request
  r1 <- append_url(api$host, "api/media_collection", my_filters1) %>% request("GET", api$auth)
  
  # parse 
  p1 <- parse(r1)
  
  # look at url
  my_url1 <- append_url(api$host, "api/media_collection", my_filters1)
  cat(URLdecode(my_url1))


# Example 2 - A simple query to Get all annotations that match annotation_set_id = 5432 and specify pagination params
{
  # Create filters
  my_filters_2 <- query_filter(name = "annotation_set_id", op = "eq", val = "5432")
  # Create other parameters
  my_params_2 <- query_params(page = "14", results_per_page = "56")
  # Append filters and parameters and send request
  r2 <- append_url(api$host, "api/annotation", my_filters_2, my_params_2) %>% request("GET", api$auth)
  # Parse
  p2 <- parse(r2, my_params_2)
  # look at url
  my_url2 <- append_url(api$host, "api/annotation", my_filters_2, my_params_2)
  cat(URLdecode(my_url2))
}

# Example 3 - Get request to export endpoint using status polling and template = data.csv to download the data as a .csv
{
  # Create filters
  my_filters_3 <- query_filter(
    name = "events",
    op = "any",
    val = query_filter(name = "id", op = "is_not_null")
  )
  # Create other params
  my_params_3 <- query_params(
    template = "data.csv",
    group_by = "pose.dep",
    include_columns = c(
      "id",
      "key",
      "path_best",
      "timestamp_start",
      "path_best_thm",
      "pose.timestamp",
      "pose.lat",
      "pose.lon",
      "pose.alt",
      "pose.dep",
      "pose.data",
      "pose.id",
      "deployment.key",
      "deployment.campaign.key",
      "deployment.id",
      "deployment.campaign.id",
      "event_log"
    )
  )
  # Append filters and parameters and send request
  r3 <- append_url(api$host,
                   "api/media_collection/13453/export",
                   my_filters_3,
                   my_params_3) %>% export("GET", api$auth, metadata_filename = "my_metadata3.json")

  # Parse
  p3 <- parse(r3, my_params_3)

    # Look at url
  my_url_3 <- append_url(api$host,
                         "api/media_collection/13453/export",
                         my_filters_3,
                         my_params_3)
  cat(URLdecode(my_url_3))
  
}

# Example 4 - Get request to export endpoint using status polling and defining limit and offset parameters
{
  # Create filters
  my_filters_4 <- query_filter(
    name = "events",
    op = "any",
    val = query_filter(name = "id", op = "is_not_null")
  )
  # Create other params
  my_params_4 <- query_params(
    limit = 100, offset = 20
  )
  # Append filters and parameters and send request
  r4 <- append_url(api$host,
                   "api/media_collection/13453/export",
                   my_filters_4,
                   my_params_4) %>% export("GET", api$auth)

  # Parse
  p4 <- parse(r4, my_params_4)
  
  # Look at url
  my_url_4 <- append_url(api$host,
                         "api/media_collection/13453/export",
                         my_filters_4,
                         my_params_4)
  cat(URLdecode(my_url_4))
  
}

# Example 5 - Get request to export endpoint using status polling and template = data.csv to download the data as a .csv with order_by
{
  # Create filters
  my_filters_5 <- query_filter(
    name = "events",
    op = "any",
    val = query_filter(name = "id", op = "is_not_null")
  )
  # Create other params
  my_params_5 <- query_params(
    template = "data.csv",
    order_by = c("pose.dep", "asc"),
    include_columns = c(
      "id",
      "key",
      "path_best",
      "timestamp_start",
      "path_best_thm",
      "pose.timestamp",
      "pose.lat",
      "pose.lon",
      "pose.alt",
      "pose.dep",
      "pose.data",
      "pose.id",
      "deployment.key",
      "deployment.campaign.key",
      "deployment.id",
      "deployment.campaign.id",
      "event_log"
    )
  )
  # Append filters and parameters and send request
  r5 <- append_url(api$host,
                   "api/media_collection/13453/export",
                   my_filters_5,
                   my_params_5) %>% export("GET", api$auth)

  # Parse
  p5 <- parse(r5, my_params_5)
  
  # Look at url
  my_url_5 <- append_url(api$host,
                         "api/media_collection/13453/export",
                         my_filters_5,
                         my_params_5)
  cat(URLdecode(my_url_5))
  
}

# Can also use append_url to combine just base url and endpoint 
simple_url <- append_url(host = api$host, endpoint = "api/annotation/5432") %>% request("GET", api$auth, filename = "simple.json")
```


