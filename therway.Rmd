
# The "r" way

# Load packages
```{r}
library(R6)
library(httr)
library(jsonlite)
library(getPass)
```

# Create class SQAPI with property: host 
```{r}
SQAPI <- R6Class("SQAPI", public = list(
  host = NULL,
  auth = NULL,
  initialize = function(host = NULL) {
    if (is.null(host)) {
      self$host <- "https://squidle.org"
    } else{
      self$host <- host
    }
    
    if (is.null(getOption("api_token"))) {
      self$auth <- getPass::getPass(msg = "Enter your API token: ")
      options(api_token = self$auth)
    } else {
      self$auth <- getOption("api_token")
    }
  }
))
```

# Helper function to recursively search list for key and return the associated value
```{r}
find_key <- function(lst, key) {
  if (is.list(lst)) {
    if (key %in% names(lst)) {
      return(lst[[key]])
    }
    for (sub in lst) {
      result <- find_key(sub, key)
      if (!is.null(result)) return(result)
    }
  }
  return(NULL)
}

# Example usage
# find_key(my_params_5, "template")
```

# Helper function to construct host + endpoint
```{r}
base_url <- function(host, endpoint){
  url <- paste0(host,"/", endpoint)
  return(url)
}
```

# Function to make query filters
# accepts name, op, val as strings - see API for details on fields
```{r}
query_filter <- function(name,
                          op,
                          val = NULL) {
  # Create the filter list and exclude 'val' if NULL
  qfilter <- list(name = name, op = op)
  if (!is.null(val)){
    qfilter$val <- val
  }
  
  return(qfilter)
}
```

# Function to make query parameters
# template, disposition, include_columns, page, results_per_page are input as strings
# limit and offset are input as intergers
# group by is input as a string 
# order by is input as a vector containing two elements the first being the field and the second being direction (either "asc" or "desc")
# single is a boolean representing whether a single result is expected (I have not tested this)
```{r}
query_params <- function(template = NULL,
                         disposition = NULL,
                         include_columns = NULL,
                         page = NULL,
                         results_per_page = NULL,
                         limit = NULL,
                         offset = NULL,
                         order_by = NULL,
                         group_by = NULL,
                         single = FALSE) {
  qparams <- list()
  q <- list()
  
  # Append to q list (parameters inside the q={} json string)
  
  # Handle 'order_by' as a character vector (e.g., c("field1", "asc"))
  json_order_by <- if (!is.null(order_by)) {
    # Check if order_by is a character vector with exactly two elements (field and direction)
    if (length(order_by) != 2 || !is.character(order_by)) {
      stop(
        "ERROR: order_by must be a character vector with exactly 2 elements, e.g., c('<fieldname>', '<order>')"
      )
    }
    order_by <- list(list(field = order_by[1], direction = order_by[2]))
    jsonlite::toJSON(order_by, auto_unbox = TRUE)
  } else {
    NULL
  }
  if (!is.null(json_order_by)) {
    q$order_by <- json_order_by
  }
  
  # Handle 'group_by' as a single field or a vector of fields
  json_group_by <- if (!is.null(group_by)) {
    if (is.character(group_by)) {
      # If it's a single field (string), make it a list
      group_by <- list(list(field = group_by))
    } else if (is.character(group_by) && length(group_by) > 1) {
      # If it's a vector of fields, process each field
      group_by <- lapply(group_by, function(x)
        list(field = x))
    } else {
      stop("ERROR: group_by must be a string or a character vector of field names.")
    }
    jsonlite::toJSON(group_by, auto_unbox = TRUE)
  } else {
    NULL
  }
  if (!is.null(json_group_by)) {
    q$group_by <- json_group_by
  }
  
  # Handle others
  if (!is.null(limit)) {
    q$limit <- limit
  }
  if (!is.null(offset)) {
    q$offset <- offset
  }
  if (!is.null(single) && single) {
    q$single <- TRUE
  }
  
  # Append to qparams list (parameters outside the q={} json string)
  # Handle include columns vector and convert to json
  json_include_columns <- if (!is.null(include_columns)) {
    jsonlite::toJSON(include_columns, auto_unbox = TRUE)
  } else {
    NULL
  }
  if (!is.null(json_include_columns)) {
    qparams$include_columns <- json_include_columns
  }
  
  # Add other parameters to the qparams list if not NULL
  for (param in c("template", "disposition", "page", "results_per_page")) {
    if (!is.null(get(param)))
      qparams[[param]] <- get(param)
  }
  return(list(q, qparams))
}
```


# Function to append query filters and paramaters to url
# input host as <nameofapiinstance>$host
# input endpoint as a string
# input query_filers and query_parameters as the *exact* output from the functions used to create them 
```{r}
append_url <- function(api,
                       endpoint,
                       query_filters = NULL,
                       query_parameters = NULL) {
  host <- api$host
  if (is.null(query_filters)) return(base_url(host, endpoint))

  # Wrap filters in a list
  filters <- list(filters = list(query_filters))

  # Initialize q list
  q <- list()

  # Process query parameters
  if (!is.null(query_parameters[[1]])) {
    q <- lapply(names(query_parameters[[1]]), function(param) {
      value <- query_parameters[[1]][[param]]
      if (!is.null(value)) {
        switch(param,
               "order_by" = jsonlite::fromJSON(value, simplifyDataFrame = FALSE),
               "group_by" = jsonlite::fromJSON(value, simplifyDataFrame = FALSE),
               value)
      }
    })
    names(q) <- names(query_parameters[[1]])
    q <- q[!sapply(q, is.null)]  # Remove NULL values
  }

  # Combine filters and q, then convert to JSON
  combined_q_json <- jsonlite::toJSON(c(filters, q), auto_unbox = TRUE)

  # Extract qparams (if they exist)
  qparams <- if (length(query_parameters) > 1) query_parameters[[2]] else list()

  # Construct URL
  url <- httr::parse_url(base_url(host, endpoint))

  # Append filters and parameters
  url$query <- c(list(q = combined_q_json), qparams)

  return(httr::build_url(url))
}
```


# Function to make the VERB request to non export endpoint
# Can pipe url in from append_url function
# input verb as string eg "GET"
# input token as <nameofapiinstance>$auth
```{r}
request <- function(verb,
                    api,
                    endpoint,
                    query_filters = NULL,
                    query_parameters = NULL,
                    body = NULL) {
  
  # Helper function to make request handling get/post/patch logic
  make_request <- function(verb, url, token, body = NULL) {
    # Handle body for POST or PATCH requests
    if (!is.null(body)) {
      # Ensure body is a valid JSON object for POST/PATCH
      body <- jsonlite::toJSON(body, auto_unbox = TRUE)
    }
    
    # Print statement
     #print(paste("Body for", verb, "request: ", body))
    
    # Make the request using httr::VERB
    response <- httr::VERB(
      verb = verb,
      url = url,
      body = body,
      config = httr::add_headers(
    "x-auth-token" =  token,
    "Content-Type" = "application/json",
    "Accept" = "application/json"
    )
    )
    
    return(response)
  }
  
  # Construct and print url
  url <- append_url(
    api = api,
    endpoint = endpoint,
    query_filters = query_filters,
    query_parameters = query_parameters
  )
  cat("Constructed URL: ")
  cat(URLdecode(url), "\n")
  
  # Retrieve token
  token <- api$auth
  
  # Make request using helper function
  response <- make_request(verb, url, token, body)
  
  # Print status
  cat("Response Status Code: ", response$status_code, "\n")
  
  # Print response object
  print(response)
  return(response)
}
```


# Function to make the VERB request to export endpoint
# input api as instance of SQAPI
# input verb and endpoint as string eg "GET"
# poll=TRUE for export endpoints
# filename as string ensuring file extenstion matched specified template (or the default json)
# metadata_filename as string - only need if template has been set as data.csv or dataframe.csv
# query_filters and query_parameters as created by functions
```{r}
## Note: Metadata only writes if template has been set as data.csv or dataframe.csv
# tidy up make polling logic into separate function
export <- function(api,
                   endpoint,
                   query_filters = NULL,
                   query_parameters = NULL,
                   verb,
                   poll = TRUE,
                   write_disk = FALSE,
                   filename = NULL,
                   metadata_filename = "metadata.json") {
  # Helper function to make an API request
  make_export_request <- function(url,
                                  verb,
                                  token,
                                  write_to_disk = FALSE,
                                  file = NULL) {
    if (write_to_disk) {
      return(
        httr::VERB(
          verb = verb,
          url = url,
          config = httr::add_headers("x-auth-token" =  token),
          httr::write_disk(file, overwrite = TRUE)
        )
      )
    } else {
      return(
        httr::VERB(
          verb = verb,
          url = url,
          config = httr::add_headers("x-auth-token" =  token),
          httr::write_memory()
        )
      )
    }
  }
  
  # Construct and print URL
  url <- append_url(
    api = api,
    endpoint = endpoint,
    query_filters = query_filters,
    query_parameters = query_parameters
  )
  cat("Constructed URL: ")
  cat(URLdecode(url), "\n")
  
  # Retrieve token
  token <- api$auth
  
  # Handle filename error
  if (write_disk && is.null(filename)) {
    stop("Error: 'write_disk' is TRUE, but 'filename' is not provided.")
  }
  
  # Initial request
  response <- make_export_request(url, verb, token, write_disk, filename)
  
  # Extract JSON response
  json <- jsonlite::fromJSON(
    content(response, 'text', encoding = "UTF-8"),
    simplifyVector = TRUE,
    flatten = TRUE
  )
  
  if (poll) {
    # Polling
    results_response <- NULL
    
    # Define URLs
    host <- paste(api$host)
    status_url <- paste0(host, json$status_url)
    result_url <- paste0(host, json$result_url)
    
    print(json$message)
    print(paste0("Status URL: ", status_url))
    print(paste0("Results URL: ", result_url))
    
    # Progress Bar
    pbar <- txtProgressBar(min = 0,
                           max = 100,
                           style = 3)
    
    while (TRUE) {
      # Check status
      status_response <- httr::VERB(
        verb = verb,
        url = status_url,
        config = httr::add_headers("x-auth-token" =  token)
      )
      
      json_status_response <- jsonlite::fromJSON(
        content(status_response, 'text', encoding = "UTF-8"),
        simplifyVector = TRUE,
        flatten = TRUE
      )
      
      # If the result is ready
      if (json_status_response$result_available ||
          json_status_response$status == "done") {
        # Call helper function to handle the write_disk logic and make request to result url
        results_response <- make_export_request(
          url = result_url,
          verb = verb,
          token = token,
          write_to_disk = write_disk,
          file = filename
        )
        
        setTxtProgressBar(pbar, 100)  # Set progress to 100% when done
        break
      } else if (json_status_response$status == "error") {
        close(pbar)
        stop("Error in processing the request.")
      }
      
      # Calculate progress
      stages <- json_status_response$progress
      total_iterations <- sum(sapply(stages, function(stage)
        if (!is.null(stage$iteration_count))
          stage$iteration_count
        else
          0))
      completed_iterations <- sum(sapply(stages, function(stage)
        if (!is.null(stage$iteration))
          stage$iteration
        else
          0))
      
      overall_progress <- if (total_iterations > 0)
        (completed_iterations / total_iterations) * 100
      else
        0
      setTxtProgressBar(pbar, overall_progress)
      
      Sys.sleep(1)  # Avoid excessive polling
    }
    
    close(pbar)
    
    # Retrieve final response
    ret_results <- results_response
  } else {
    ret_results <- response
  }
  
  
  # Handle metadata if it's a CSV file
  if (grepl("data.csv|dataframe.csv", url)) {
    # Clean endpoint for filename
    safe_endpoint <- gsub("[^a-zA-Z0-9_]", "_", endpoint)
    
    # Make metadata_filename based on filename or endpoint
    metadata_filename <- if (!is.null(filename)) {
      paste(filename, metadata_filename, sep = "_")
    } else {
      paste(safe_endpoint, metadata_filename, sep = "_")
    }
    
    meta <- ret_results$headers$`x-content-metadata`
    if (!is.null(meta)) {
      writeLines(meta, metadata_filename)
      cat("See metadata file: ", metadata_filename, "\n")
    }
  }
  
  cat("\nResponse Status Code: ", response$status_code, "\n")
  return(ret_results)
}

```


```{r}

parse <- function(response, query_params = NULL) {
  
  if (is.null(query_params)){
    template <- "default"}
  # Finds value associated with key "template"
  template <- find_key(query_params, "template")
  # Handle null templace as "default"
    if (is.null(template)) {
    template <- "default"
  }
  parsed <- switch(template,
                   "data.csv" = {
                     raw_text <- rawToChar(response$content)
                     read.csv(textConnection(raw_text))
                   },
                   "dataframe.json" = {
                     jsonlite::fromJSON(httr::content(response, "text", encoding = "UTF-8"))
                   },
                   {
                     "default" = 
                     {jsonlite::fromJSON(httr::content(response, "text", encoding = "UTF-8"))}
                   })
  
  return(parsed)
}
```


# Updated usage
```{r}
# Lib for pipes
library(magrittr)

# Initialize api to handle authentication and host (using default host)
## Will prompt for token
api <- SQAPI$new()

# Example 0 - A simple query
{
  # Create filters
  my_filters <- query_filter(name = "id", op = "eq", val = "5432")
  # Send request
  r <- request(api = api, endpoint = "api/annotation_set", query_filters = my_filters, verb = "GET")
  # parse
  p <- parse(r)
  
}

# Example 1 - A nested query to Get all media_collections that contain media from a specific campaign matching the key "Batemans201011"
{
  # Create filters (nested)
  my_filters1 <- query_filter(
    name = "media",
    op = "any",
    val = query_filter(
      name = "deployment",
      op = "has",
      val = query_filter(
        name = "campaign",
        op = "has",
        val = query_filter(name = "key", op = "eq", val = "Batemans201011")
      )
    )
  )
  # Send request
  r1 <- request("GET", api, "api/media_collection", my_filters1)
  
  # parse 
  p1 <- parse(r1)}

# Example 2 - A simple query to Get all annotations that match annotation_set_id = 5432 and specify pagination params
{
  # Create filters
  my_filters_2 <- query_filter(name = "annotation_set_id", op = "eq", val = "5432")
  # Create other parameters
  my_params_2 <- query_params(page = "14", results_per_page = "56")
  # Append filters and parameters and send request
  r2 <- request("GET", api, "api/annotation", my_filters_2, my_params_2)
  # Parse
  p2 <- parse(r2, my_params_2)

}

# Example 3 - Get request to export endpoint using status polling and template = data.csv to download the data as a .csv
{
  # Create filters
  my_filters_3 <- query_filter(
    name = "events",
    op = "any",
    val = query_filter(name = "id", op = "is_not_null")
  )
  # Create other params
  my_params_3 <- query_params(
    template = "data.csv",
    group_by = "pose.dep",
    include_columns = c(
      "id",
      "key",
      "path_best",
      "timestamp_start",
      "path_best_thm",
      "pose.timestamp",
      "pose.lat",
      "pose.lon",
      "pose.alt",
      "pose.dep",
      "pose.data",
      "pose.id",
      "deployment.key",
      "deployment.campaign.key",
      "deployment.id",
      "deployment.campaign.id",
      "event_log"
    )
  )
  # Send request
  r3 <- export(
    api = api,
    endpoint = "api/media_collection/13453/export",
    query_filters = my_filters_3,
    query_parameters = my_params_3,
    verb = "GET",
    metadata_filename = "my_metadata3.json"
  )

  # Parse
  p3 <- parse(r3, my_params_3)
  
  # Send request and write to disk
    r3_write_disk <- export(
    api = api,
    endpoint = "api/media_collection/13453/export",
    query_filters = my_filters_3,
    query_parameters = my_params_3,
    verb = "GET",
    write_disk = TRUE,
    filename = "media_collection_13453",
    metadata_filename = "metadata3.json"
  )
}

# Example 4 - Get request to export endpoint using status polling and defining limit and offset parameters
{
  # Create filters
  my_filters_4 <- query_filter(
    name = "events",
    op = "any",
    val = query_filter(name = "id", op = "is_not_null")
  )
  # Create other params
  my_params_4 <- query_params(
    limit = 100, offset = 20
  )
  # Send request
  r4 <-  export(
    api = api,
    endpoint = "api/media_collection/13453/export",
    query_filters = my_filters_4,
    query_parameters = my_params_4,
    "GET"
  )

  # Parse
  p4 <- parse(r4, my_params_4)
  
}

# Example 5 - Get request to export endpoint using status polling and template = data.csv to download the data as a .csv with order_by
{
  # Create filters
  my_filters_5 <- query_filter(
    name = "events",
    op = "any",
    val = query_filter(name = "id", op = "is_not_null")
  )
  # Create other params
  my_params_5 <- query_params(
    template = "data.csv",
    order_by = c("pose.dep", "asc"),
    include_columns = c(
      "id",
      "key",
      "path_best",
      "timestamp_start",
      "path_best_thm",
      "pose.timestamp",
      "pose.lat",
      "pose.lon",
      "pose.alt",
      "pose.dep",
      "pose.data",
      "pose.id",
      "deployment.key",
      "deployment.campaign.key",
      "deployment.id",
      "deployment.campaign.id",
      "event_log"
    )
  )
  # Append filters and parameters and send request
  r5 <- export(
    api = api,
    endpoint = "api/media_collection/13453/export",
    query_filters = my_filters_5,
    query_parameters = my_params_5,
    verb = "GET"
  )

  # Parse
  p5 <- parse(r5, my_params_5)
  
  
}

```
# POST example
```{r}
api <- SQAPI$new()
post_me <- list(
    "name" = "API test 01",
    "description" = "Testing API-created media_collection",
    "user_id"= 007
)

post <- request(verb = "POST", api = api, endpoint = "api/media_collection", body = post_me)

#then get it?
test <- query_filter(name = "name", op = "eq", val = "API test 01")
r6 <- request("GET", endpoint = "api/media_collection", query_filters = test, api = api) %>% parse()
#seems to work... will add more later
```


